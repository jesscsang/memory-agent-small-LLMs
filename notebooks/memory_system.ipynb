{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Environment Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip --quiet install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OLAMA_BASE_URL = os.getenv('OLAMA_BASE_URL')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load/Setup Vector Database -- Chroma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U langchain-ollama\n",
    "%pip install --quiet -U langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize the embeddings\n",
    "embeddings = OllamaEmbeddings(\n",
    "    base_url=OLAMA_BASE_URL,\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "persist_directory = \"./chroma_langchain_db\"\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"long_term_memories\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory,  # Where to save data locally, remove if not necessary\n",
    "    create_collection_if_not_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b757c7b3-a01c-4ff5-a44f-4f2b23e3faea',\n",
       " '893ff4aa-ce4c-4563-840a-8848c5e71955',\n",
       " 'af1ac112-b001-4b0b-9708-601964d6845b',\n",
       " '41b86881-f393-4d4c-a2e7-0da9156b7b00',\n",
       " '56351758-9260-4678-a582-c3a9318866b5']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from uuid import uuid4\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I love pizza\",\n",
    "    metadata={},\n",
    ")\n",
    "document_2 = Document(\n",
    "    page_content=\"I prefer Korean food\",\n",
    "    metadata={},\n",
    ")\n",
    "document_3 = Document(\n",
    "    page_content=\"I love spicy food\",\n",
    "    metadata={},\n",
    ")\n",
    "document_4 = Document(\n",
    "    page_content=\"I am studying computer science\",\n",
    "    metadata={},\n",
    ")\n",
    "document_5 = Document(\n",
    "    page_content=\"I am a student\",\n",
    "    metadata={},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "]\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='e77facaa-ef3d-4128-b853-1ed69197ab34', metadata={}, page_content='Hello'), 1.0494743881539488), (Document(id='df95c508-d11a-43be-933a-96a382ee8bdc', metadata={}, page_content='I am a student'), 1.1332038151490709), (Document(id='56351758-9260-4678-a582-c3a9318866b5', metadata={}, page_content='I am a student'), 1.1332038151490709)]\n",
      "* [SIM=1.049474] Hello [{}]\n",
      "* [SIM=1.133204] I am a student [{}]\n",
      "* [SIM=1.133204] I am a student [{}]\n"
     ]
    }
   ],
   "source": [
    "# Test Query\n",
    "query = \"what's my name\"\n",
    "\n",
    "# results = vector_store.similarity_search(query, k=3, filter=None)\n",
    "results = vector_store.similarity_search_with_score(query, k=3, filter=None)\n",
    "print(results)\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    base_url=OLAMA_BASE_URL,\n",
    "    model=\"llama3.2:1b\",\n",
    "    temperature=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Conversation Threads: Multiple Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage, trim_messages\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Sequence\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from uuid import uuid4\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"You are a helpful assistant. <memories>{memories}</memories>\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=256,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if isinstance(last_msg, HumanMessage):\n",
    "        query = last_msg.content\n",
    "        results = vector_store.similarity_search_with_score(query, k=2)\n",
    "        memories = \"\\n\".join(f\"{str(res.page_content)}\" for res, _ in results)\n",
    "\n",
    "        # Create memory\n",
    "        doc = [Document(page_content=query, metadata={},)]\n",
    "        uuid = [str(uuid4())]\n",
    "        vector_store.add_documents(documents=doc, ids=uuid)\n",
    "    else:\n",
    "        memories = \"\"\n",
    "    \n",
    "    prompt = prompt_template.invoke(\n",
    "        {\n",
    "            \"messages\": trimmed_messages,\n",
    "            \"memories\": memories\n",
    "        }\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    return {\"messages\": [response] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = InMemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Message as it is Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U transformers\n",
    "%pip install --quiet -U torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat with TESS (type 'exit' to end the conversation)\n",
      "USER: Hello\n",
      "TESS: It|'s| nice| to| meet| you|.| Is| there| anything| I| can| help| you| with| or| would| you| like| to| talk| about| something| in| particular|?||\n",
      "USER: What are the top 10 most spicy peppers?\n",
      "TESS: When| it| comes| to| spice| levels|,| here|'s| a| list| of| the| top| |10| most| commonly| used| and| revered| chili| peppers|:\n",
      "\n",
      "|1|.| **|Car|olina| Reaper|**| (|2|,|200|,|000|-|3|,|200|,|000| Sc|ov|ille| Heat| Units| (|SH|U|)):| Known| for| its| intense| heat| and| unique| flavor|.\n",
      "|2|.| **|Tr|inidad| Mor|uga| Sc|orpion|**| (|1|,|469|,|000|-|2|,|486|,|000| SH|U|):| A| Trinidad|ian| pepper| known| for| its| intense|,| electric| heat|.\n",
      "|3|.| **|N|aga| J|ol|okia|**| (|855|,|000|-|1|,|041|,|427| SH|U|):| Also| known| as| the| Ghost| Pepper|,| this| Indian| pepper| is| not| for| the| faint| of| heart|.\n",
      "|4|.| **|Infinity| Chili|**| (|1|,|382|,|118|-|2|,|160|,|000| SH|U|):| A| hybrid| chili| bred| to| be| even| hotter| than| the| N|aga| J|ol|okia|.\n",
      "|5|.| **|Sc|otch| Bon|net|**| (|100|,|000|-|350|,|000| SH|U|):| A| Caribbean| pepper| known| for| its| intense| heat| and| sweet| flavor|.\n",
      "|6|.| **|H|aban|ero|**| (|100|,|000|-|350|,|000| SH|U|):| A| popular| chili| pepper| used| in| many| hot| sauces| and| dishes|.\n",
      "|7|.| **|C|ay|enne| Pepper|**| (|30|,|000|-|50|,|000| SH|U|):| A| common| ingredient| in| many| recipes|,| known| for| its| bright| red| color| and| intense| heat|.\n",
      "|8|.| **|Ghost| Pepper| (|B|h|ut| J|ol|okia|)**| (|855|,|000|-|1|,|041|,|427| SH|U|):| As| mentioned| earlier|,| this| Indian| pepper| is| not| for| the| faint| of| heart|.\n",
      "|9|.| **|F|res|no| Pe|ppers|**| (|10|,|000|-|23|,|000| SH|U|):| A| mild| to| medium|-hot| pepper| commonly| used| in| American| cuisine|.\n",
      "|10|.| **|Red| Hab|an|ero|**| (|100|,|000|-|350|,|000| SH|U|):| A| variation| of| the| Hab|an|ero| pepper|,| known| for| its| intense| heat| and| fruity| flavor|.\n",
      "\n",
      "|Keep| in| mind| that| Sc|ov|ille| Heat| Units| are| subjective| and| can| vary| depending| on| factors| like| growing| conditions| and| preparation|.| These| peppers| are| all| known| for| their| intense| heat|,| so| use| them| sparing|ly| if| you|'re| not| comfortable| with| extreme| spice| levels|!\n",
      "\n",
      "|Would| you| like| to| know| more| about| any| of| these| peppers| or| explore| other| spicy| topics|?||\n",
      "USER: exit\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "print(\"Chat with TESS (type 'exit' to end the conversation)\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    print(\"USER:\", user_input)\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    input_messages = [HumanMessage(user_input)]\n",
    "    print(\"TESS: \", end=\"\")\n",
    "    for chunk, metadata in app.stream(\n",
    "        {\"messages\": input_messages},\n",
    "        config,\n",
    "        stream_mode=\"messages\",\n",
    "    ):\n",
    "        if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "            print(chunk.content, end=\"|\")\n",
    "    print(end='\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, how are you doing?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the top 10 most spicy peppers?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are ten of the hottest peppers in the world, ranked by their Scoville heat units (SHU):\n",
      "\n",
      "1. **Carolina Reaper** - 1,569,300 SHU\n",
      "2. **Trinidad Moruga Scorpion** - 1,469,000 SHU\n",
      "3. **Naga Viper** - 1,382,118 SHU\n",
      "4. **Naga Jolokia** - 855,000-1,041,427 SHU (Note: the exact range can vary depending on factors like growing conditions and preparation)\n",
      "5. **Ghost Pepper (Bhut Jolokia)** - 855,000-1,041,427 SHU\n",
      "6. **Naga Jolokia** - 855,000-1,041,427 SHU (same as above)\n",
      "7. **Scotch Bonnet** - 350,000-500,000 SHU\n",
      "8. **Calypso** - 200,000-300,000 SHU\n",
      "9. **Infinity Chili** - 223,000-233,000 SHU\n",
      "10. **Fresno Pepper** - 225,000-350,000 SHU\n",
      "\n",
      "Please note that the Scoville scale is subjective and can vary depending on factors like the pepper's ripeness, preparation, and individual tolerance. These rankings are approximate and based on average values.\n",
      "\n",
      "Would you like to know more about spicy peppers or have any specific questions?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It's nice to meet you. Is there anything I can help you with or would you like to talk about something in particular?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the top 10 most spicy peppers?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "When it comes to spice levels, here's a list of the top 10 most commonly used and revered chili peppers:\n",
      "\n",
      "1. **Carolina Reaper** (2,200,000-3,200,000 Scoville Heat Units (SHU)): Known for its intense heat and unique flavor.\n",
      "2. **Trinidad Moruga Scorpion** (1,469,000-2,486,000 SHU): A Trinidadian pepper known for its intense, electric heat.\n",
      "3. **Naga Jolokia** (855,000-1,041,427 SHU): Also known as the Ghost Pepper, this Indian pepper is not for the faint of heart.\n",
      "4. **Infinity Chili** (1,382,118-2,160,000 SHU): A hybrid chili bred to be even hotter than the Naga Jolokia.\n",
      "5. **Scotch Bonnet** (100,000-350,000 SHU): A Caribbean pepper known for its intense heat and sweet flavor.\n",
      "6. **Habanero** (100,000-350,000 SHU): A popular chili pepper used in many hot sauces and dishes.\n",
      "7. **Cayenne Pepper** (30,000-50,000 SHU): A common ingredient in many recipes, known for its bright red color and intense heat.\n",
      "8. **Ghost Pepper (Bhut Jolokia)** (855,000-1,041,427 SHU): As mentioned earlier, this Indian pepper is not for the faint of heart.\n",
      "9. **Fresno Peppers** (10,000-23,000 SHU): A mild to medium-hot pepper commonly used in American cuisine.\n",
      "10. **Red Habanero** (100,000-350,000 SHU): A variation of the Habanero pepper, known for its intense heat and fruity flavor.\n",
      "\n",
      "Keep in mind that Scoville Heat Units are subjective and can vary depending on factors like growing conditions and preparation. These peppers are all known for their intense heat, so use them sparingly if you're not comfortable with extreme spice levels!\n",
      "\n",
      "Would you like to know more about any of these peppers or explore other spicy topics?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "state = app.get_state(config).values\n",
    "for message in state[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
